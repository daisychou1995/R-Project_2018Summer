knitr::opts_chunk$set(echo = TRUE)
summary(cars)
<li>Parish</li>
# æåç¨* == ç�æ¼   != ä¸ç�æ¼e.g."character" == "character" # æç§å�é¦é åºæ¯å¤§å°(æå¾çå�æ¯æå¤§,å�é¦ç¸ååæ¯å�æ¯æ¸é)
e.g.TRUE < FALSE
?read.csv
setwd("~/")
setwd("D:/CSX/R-Project_2018Summer")
setwd("D:/CSX/R-Project_2018Summer")
setwd("D:/CSX/R-Project_2018Summer/week3/DATA/ALL")
FashionDATA = read.csv(file="sample_submission.csv", header=TRUE, sep=",")
FashionDATA = read.csv(file="D:/CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv")
sample_submission
sample_submission.csv
FashionDATA = read.csv("D:/CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv")
sample_submission.csv
FashionDATA = read.csv("sample_submission.csv")
FashionDATA = read.csv("D:/CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv")
D:/CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv
CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv
"D:/CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv"
D:/CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv
D:CSX/R-Project_2018Summer/week3/DATA/ALL/sample_submission.csv
FashionDATA = read.csv("D:/CSX/R-Project_2018Summer/week3/DATA/ALL/train.csv")
train.csv
FashionDATA = read.csv('./DATA/all/train.csv')
FashionDATA = read.csv('./DATA/ALL/test.csv')
FashionDATA = read.csv('./DATA/ALL/test.csv')
install.packages("knitr")
install.packages("knitr")
FashionDATA = read.csv('./DATA/ALL/test.csv')
view(FAshionDATA)
View(FashionDATA)
?ggplot2
AnimalDATA = read.csv('./DATA/ALL/test.csv')
??
View(AnimalDATA)
View(AnimalDATA)
View(FashionDATA)
head(data)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
install.packages("RCurl")
install.packages("XML")
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
from <- 1853 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(dplyr)
install.packages("dplyr")
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
getdoc <- function(url)
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
html <- htmlParse( GET(url) )
part <- strsplit( temp, split=" ", fixed=T )
timestamp <- part[[1]][4]
getdoc
html
sapply(data, getdoc)
setwd("D:/CSX/R-Project_2018Summer/week3/DATA")
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
from <- 1852 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
from <- 1844 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
knitr::opts_chunk$set(echo = TRUE)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
from <- 1844 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
setwd("D:/CSX/R-Project_2018Summer/week3")
knitr::opts_chunk$set(echo = TRUE)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
from <- 1844 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
timestamp
timestamp
timestamp[1][1]
getdoc
url
html
doc
time
empty.dump()
temp
part
timestamp
names
name
setwd("D:/CSX/R-Project_2018Summer/week3")
```{r setup, include=FALSE}
```{r}
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
install.packages("NLP")
install.packages("NLP")
knitr::opts_chunk$set(echo = TRUE)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
from <- 1844 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
from <- 1844 # 2018-07-06
to   <- 1858 # 2018-07-17
prefix = "https://www.ptt.cc/bbs/Japandrama/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
